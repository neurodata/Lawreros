Getting Started:

ndmg currently runs inside a docker container, stored here on dockerhub: neurodata/ndmg_dev:latest

The ndmg pipeline can be used to generate connectomes as a command-line utility on BIDS datasets with the following command:

ndmg_bids /input/bids/dataset /output/directory participant

Note that more options are available which can be helpful if running on the Amazon cloud, which can be found and documented by running ndmg_bids -h. If you do not have a BIDS organized dataset, you an use a slightly more complicated interface which is made available and is documented with ndmg_pipeline -h.
If running with the Docker container shown above, the entrypoint is already set to ndmg_bids, so the pipeline can be run directly from the host-system command line as follows:
docker run -ti -v /path/to/local/data:/data bids/ndmg /data/ /data/outputs participant


Questions/Difficulties:
- In ndmg_bids.session_level, what is being done in args = [[ dw, bval, bvec, anat,...] for (dw, bval, bvec, anat) in zip(dwis, bvals, bvecs, anats)] ?
- What on earth is bids_utils.flatten() doing? It appears to just retrieve the path to the output directory?
- In ndmg_dwi_pipeline, around line 210 the variable 'nodif_B0_iso_path' is assigned a value. This appears to never be used?
- What is the purpose of gen_utils.execute_cmd? It appears to open a bash command and and execute whatever string is fed to it.
- In gen_utils.reorient_t1w(), in the first several lines a random string is generated and put into the path for the t1w files. Why do that?
- gen_utils.reorient_dwi() and reorient_t1w( ) runs several command line fsl functions
- In gen_utils.make_gtab_and_bmask( ) 'fslroi' and 'bet' commands are run from the command line
- gen_reg.gen_tissue() executes 'fslmaths' commands
- reg_utils.t1w_skullstrip executes '3dSkullStrip' commands
- the gen_reg.dmri_reg class contains the namer class, is there anyway to just combine them at the beginning?
- reg_utils.segment_t1w executes 'fast' commands
- Pretty much all of reg_utils.py executes command line AFNI or FSL functions
- gen_reg.dmri_reg.gen_tissue executes 'fslmaths' command
- gen_reg.dmri_reg.t1w2dwi_align uses the 'convert_xfm' command, need to look into whether that is part of fsl
- in gen_track.run_track.prep_track the tiss_class variable is assigned 'act', which makes the following if and elif useless
- reg_utlis.py has multiple duplicate functions in it, like segment_t1w
- 

The notes below give a simplified explaination of the process the pipeline follows:

ndmg_bids.py
Purpose: Starting point of the ndmg pipeline, assuming you are using a BIDS organized dataset

	main( )
		Inputs:
			Run [ndmg_bids -h] to get a full list of potential inputs. Required inputs are:
			bids_dir = path to the BIDS formated directory containt the input dataset
			output_dir = desired location of the output directories
			{participant, group} = level of the analysis that will be performed
			
		Description:
			1. Reads in the inputs given by the user
			2. Determines if a s3 bucket is being called and if the path provided is valid. If it is then it reads it in, using any subject/session specifications you've made.
			3. Passes inputs onto session_level( ) for further analysis
		Outputs:
			User input parameters



	session_level( )
		Inputs:
			User input parameters from main( )
		Description:
			1. Sends atlas directory, modality, and voxel_size to get_atlas( )
			2. Recieves labels, reference brain, reference mask, atlas brain and lv_mask from get_atlas( )
			3. Sorts through the reference files to only select the ones that match atlas_select's atlas (i.e. deskian)
			4. Uses sweep_directory( ) to get the paths for the dwi, anat, bval and bvec files.
			5. Depending on the modality specified by the user:
				1. For dwi data, create a list 'args' which contains the location of the dwi, bvec, bval, anatomical, reference, mask, and output directory
				2. For func data, create a list 'args' which contains the locations of the func, anatomical, reference, atlas brain, atlas brain mask, lv_mask, labels, and output directory 
			6. Print out what is in args to double-check paths and files
			7. Send relevant files to ndmg_dwi_worker()
			8. If the modality is set to func and debug is False, remove files
		Outputs:
			None
			
			
	get_atlas( )
		Inputs:
			atlas_dir = the directory containing the atlases
			modality = what you are analyzing, "dwi" or "func"
			vox_size = the voxel size to use for template registrations
		Description:
			1. Check if specified voxel size is 2mm or 1mm, if it is then set dimension 'dims' to '2x2x2' or '1x1x1' respectfully. If voxel size given is different from either of those choices, raise an Error
			2. If the modality is set to 'dwi', make sure that the atlas directory exists (if it doesn't, download it from github.com/neurodata/neuroparc.git) then go throught the atlas directory and assign:
				1. atlas = path to T1 weighted mask of reference brains of the given resolution
				2. atlas_mask = path to T1 weighted mask of reference brains of the given resolution
				3. labels = path to labeling files for various areas of the brain depending on your atlas choice
			3. If the modality is set to 'func', then go through the atlas directory to find the same info [CURRENTLY COMMENTED OUT]
			4. Check to make sure that all the reference files exist before organizing them to return to session_level( )
		Outputs:
			labels = list of locations of label files for atlases of relevant voxel resolution
			atlas = location of atlas brain
			atlas_mask = location of atlas brain_mask
			atlas_brain = [CURRENTLY NOT MADE]
			lv_mask = [CURRENTLY NOT MADE, DEFAULT = NoneType]





ndmg_dwi_pipeline.py
Purpose: To create a brain connectome graph from MRI data. This program is where the majority of the analysis is facilitated.

	ndmg_dwi_worker( )
		Inputs:
		    
		Description:
			1. Print all inputs received from ndmg_bids.py and double check that all variables are assigned something
		    	2. Create “namer”, a variable of the name_resource class in bids_utils.py. Namer contains all of the path and settings information for the desired run. It includes: subject, anatomical scan, session, run number, task, resolution, output directory. It also contains functions to edit and recall information contained within
		    	3. Check if the output directory exists, if not then create the directory
		    	4. Create the directory tree required for placing the outputs of the analysis and add them to namer
		    	5. Create streamline and connectome output file/directory paths
		    	6. Begin Preprocessing by performing eddy correction, deleting prexisting preprocessed dwi files if skipeddy is False. Then commands to run FSL’s eddy_correct program are written into the terminal and the system is then asked to execute the task on the terminal using os.system(cmd). Eddy correct data is placed into the output directory.
			7. Copy the input bval and bvec files into the output/prep_dwi directory for future use
    			8. Use dipy.io to check that the bvec and bval files aren’t corrupted. This is done by making sure that anywhere in the array bvals = 0, bvecs = 0. If there is any point where bvals > 50 and the corresponding bvector is [0,0,0], throw an error.
    			9. Rescale the bvecs using rescale_bvec.py in ndmg.preproc, which works by:
        			1. making sure that the bvec array has the dimensions X rows and 3 columns, otherwise it transposes it
        			2. normalizing any value in in bvec that doesn’t have a vector norm close to 0
        			3. save rescaled bvec data to bvec_scaled.bvec file in /output/dwi/preproc/
    			10. Determine the orientation of the preprocessed dwi files by sending them to gen_utils.reorient_dwi( ) and receiving the potentially changed dwi_prep and bvec file paths
    			11. Check the voxel resolution using gen_utils.match_target_vox_res( ) and potentially reslice dwi_prep images
    			12. Build a gradient table using gen_utils.make_gtap_and_bmask( )
    			13. Get b0 header and affine from dwi eddy corrected file
			14. [if skipreg = True, skip this step] Begin the registration of the structural (t1w) mri data by checking to make sure that there are no pre-existing directories with names of what the program will be using. If there are, this program will delete it.
    			15. Reorient the t1w data if necessary by using gen_utlis.reorient_t1w( ), getting the potentially edited path to t1w data back
    			16. Determine where to calculate the tractography (reg_style): native = map atlas to subject, native-DSN = map streamlines to atlas, mni = map subject to atlas
				1. If reg_style = native or native-DSN. Create gen_reg.dmri_reg class 'reg', this class contains many methods that will be used
				2. [If skipreg = False] Use reg.gen_tissue to extract the brain from the raw t1w image, create WM, GM, and CSF masks, reslices all 4 files to the target voxel resolution and extracts the white matter edge, saving all masks created
				3. [if skipreg = False] Use reg.t1w2dwi_align to create several transform matricies and warp coefficient files for mapping t1w -> dwi, t1w -> mni and their inverses
				4. [if skipreg = False] Use reg.tissue2dwi_align to create several masks of grey-matter, white-matter, ventricles, and csf in the subject's dwi space
				5. Begin tensor fitting and fiber tractography by creating a seeds list from the white-matter grey-matter dwi mask
				6. Create 'tract', a variable of the gen_track.run_track class for deterministic tractography in native space. This variable contains the paths for the masks, brain, seeds, and gtab in the participant's dwi space
				7. run trct.run() in order to get the ArraySequence of tractography tracks raw data and assign it to the variable 'streamlines'
				8. go through the streamlines using dipy.tracking.streamline.Streamlines and remove any streamlines with a length less than 40. Then create a .trk streamline file in .../output/dwi/fiber/streamlines.trk
				9. If reg_style = 'native_dsn' then use gen_track.tens_mod_fa_est to create a tensor FA image to use for registrations and save it at .../output/dwi/preproc/tensor_fa.nii.gz
					1. Send the streamlines and the FA image to gen_reg.direct_streamline_norm in order to get the warped streamlines and the path to the created tractogram file .../dwi/fiber/streamlines_dsn.trk
					[Note: inside direct_streamline_norm is where DSN QC plotting occurs]
					
				1. If reg_style = mni, use gen_utils.match_target_vox_res to reslice the t1w image to the right voxel size
				2. [Come back to notate when running the pipeline again]
				3.
			17. Begin connectome estimation by first determining which registration style you are using:
				1. If reg_style = native_dsn, use gen_utils.reorient_img to reorient the labeled atlas brain to RAS+ orientation
				2. Use gen_utils.match_target_vox_res to reslice the reoriented atlas brain to the desired voxel resolution
				3. Use gen_reg.atlas2t1w2dwi_align to transform the labeled atlas brain into dwi space
				4. 
				
				1. if reg_style = native,
			18. Then use 
			
		Outputs:



gen_utils.py
Purpose: General functions to be used during the pipeline

	reorient_dwi( )
		Inputs:
			dwi_prep = location of the eddy corrected dwi data
			bvecs = location of the rescaled bvec file
			namer = the namer variable containing all relevant naming data
		Description:
			1. load in the eddy correct dwi file using nibabel.load
			2. Then use nibabel.aff2axcodes to get the axial direction codes from the dwi file, then nibabel.as_closest_canonical which reorients the input dwi file to RAS orientation (left to right, posterior to anterior, inferior to superior)
			3. Use reg_utils.normalize_xform to [ ]
			4. If the newly normalized image does not match the original input image, use nibabel to reorient the b-vector information and save it into a file
			5. Return the paths of the changed dwi and bvec files
		Outputs:
			out_fname = path to potentially reoriented dwi data
			out_bvec_fname = path to b-vector file, potentially reorientated if dwi data was

	match_target_vox_res( )
		Reslices input MRI file if it doesn’t match the targeted voxel resolution. Can take dwi or t1w scans.
		Inputs:
			img_file = path to image file you want to analyze
			vox_size = voxel size you
			namer = the namer variable containing all relevant naming data
			sens = the format of the image file
		Description:
    			1. imports reslice from dipy.align.reslice
    			2. load the image file and get various parameters from it (affine, header, zooms)
    			3. determine if the given voxel size (zooms) is either 1mm or 2 mm. If it is not then:
        			1. create the path were the resliced images will go, .../output/<sens>/preproc/<img_file>_res.nii.gz
        			2. run dipy’s reslice function on the data to get it to the new resolution, then take the data and nibable.Nifti1Image to convert the data into a nifti image and save it to the previously made path
				
				1. If voxel size is 1mm or 2mm, create the path .../output/<sens>/preproc/<img_file>_nores.nii.gz
				2. save the input dwi file there
			4. Return the path to the potentially resliced dwi image file
		Outputs:
			img_file = path the the image file that may have been resliced

	make_gtab_and_bmask( )
		Takes bval and bvec files and produces a structure in dipy format
		Inputs:
			fbval = path to bval
			fbvec = path to bvec 
			dwi_file = path to dwi file
			outdir = path to were you want the output files saved
		Description:
    			1. read in bval and bvec data
    			2. create a gradient table from that data using gradient_table from dipy and set the b0 threshold to the minimum bval value
    			3. Locate where the b0 indices are by looking for where in bval it equals the threshold
   			4. Extract and combine all the b0s collected from the dwi file using fslroi and saving the output filed into /output/dwi/preproc/#_B0.nii.gz
    			5. Take all the b0s and average them and save the resulting image into /output/dwi/preproc/nodif_B0.nii.gz
    			6. Then take the average image and generate a b0 brain mask using bet
    			7. Return relevant data
		Outputs:
			gtab = gradient table
			nodif_B0 = path to averaged b0 image
			nodif_B0_mask = b0 brain mask
			
			
gen_reg.py
Purpose:

	dmri_reg <Class>
		Creates a variable containing all the pathing information required for tractography
		Inputs:
			namer = the namer variable containing BIDS directory tree
			nodif_B0 = path to the b0 brain mask
			t1w_in = path to t1w scan to be analyzed
			vox_size = voxel size (in the form of ‘2mm’)
			simple = simple
		Description:
			1. take in relevant pathing strings and create an expansive list of paths for the various outputs about to be generated by the pipeline
    			2. Run class modules below for tractography analysis
			
			gen_tissue():
				Inputs:
					none
				Description:
					1. Extracts brain from raw t1w data and saves it as a seperate file with the "AFNI's 3dSkullStrip algorithm" in reg_utils.t1w_skullstrip()
					2. Takes the extracted brain and segments it into probability maps using reg_utils.segment_t1w(), which runs FSL's FAST to segment the image into the grey matter, white matter, and CSF probability maps (masks). It returns the location of the segmented files ('.../output/anat/preproc/t1w_seg/pve*')
					3. Use gen_utils.match_target_vox_rex( ) to reslice the extracted t1w brain image, white matter mask, grey matter mask, and csf mask and save them
					4. Filter the white-matter mask so that any value below 0.2 is ignored (this ignores all non-white-matter) and use fslmaths to extracte the white matter edge and save it					
				Output:
					
			t1w2dwi_align():
				Inputs:
					none
				Description:
					1. Use reg_utils.align() to run FSL's flirt command on the extracted t1w brain to allign it with the MNI template of the same voxel resolution and save the transform matrix to '.../output/tmp/reg_m/xfm_t1w2mni_init.mat'
					2. Attempt to perform a non-linear registration of the t1w image to the MNI template using reg_utils.align_nonlinear, which uses 'fnirt' to attempt to register the image and create an output image, warped t1w image
						1. If successful, take the warp coefficient file for going from t1w -> mni and invert it using reg_utils.inverse_warp to get a warp coefficient file for going from mni -> t1w
						2. Use the 'convert_xfm' function from fsl to get the transform matrix from mni -> t1w by inverting the transform matrix of t1w -> mni.
						
						1. If not successful, use reg_utils.align() to linearly align t1w to mni and create the t1w -> mni transform matrix (no warp coefficient files made this way)
					3. Align t1w to dwi by using reg_utils.align() again, but with the averaged b0 image file and the extracted t1w brain
					4. Use the 'convert_xfm' function from fsl to get the transform matrix from t1w -> dwi and invert it to dwi -> t1w
					5. Attempt to run FLIRT's BBR registration to mat t1w -> dwi by running ret_utils.align() to map the averaged b0 image onto the t1w brain
						1. If successful, use fsl's 'convert_sfm' command to invert the resulting transform matrix from dwi -> t1w to t1w -> dwi
						2. Run ret_utils.align() again, using the t1w -> dwi matrix to map the t1w brain onto the averaged b0 image. This saves the newly mapped t1w image and the transform matrix used to create it.
						
						1. If not successful, simply run reg_utils.align to do the same thing as step 2 of the successful outcome.
				Output:
				
			tissue2dwi_align():
				Inputs:
				
				Description:
					1. Executes FSL's 'fslroi' and 'fslmaths' command to create a ventricle mask for the chosen MNI atlas
					2. use reg_utils.align in order to create a tranform matrix from the atlas onto the MNI t1w image
					3. use reg_utils.applyxfm, which executes FSL's 'flirt' command in order create an aligned atlas to the MNI t1w image
					5. if the attempt to perform a non-linear registration of the t1w image to the MNI template was successful (see t1w2dwi_align), apply the warp coefficient file from mni -> t1w onto the ventricle mask to warp it into the subject's t1w space and save the resulting image using reg_utils.apply_warp
					6. use reg_utils.applyxfm to map the ventricle, white matter, grey matter, and csf masks onto the averaged b0 image, creating masks in the subjects dwi space for each of them
					7. proceed to threshold these masks by converting them to binary (masked area = 1, everything else = 0) and save the resulting files
					8. use 'fslmaths' to create a mask containing both the ventricles and csf
					9. use 'fslmaths' to create a grey matter-white matter interface image
				
				Output:
				
			atlas2t1w2dwi_align():
				Inputs:
					atlas = path to atlas file you want to use
					dsn = whether or not you are using native-dsn
				Description:
					1. Takes path of atlas file and use use it to create temp and output file names for the file generate dby this function
					2. Uses reg_utils.align to align the atlas to the t1 aligned mni file (file that has been mapped onto the t1w file, called alligned_atlas_t1mni)
					3. If simple!= False (meaning you want to attempt non linear template registration), uses reg_utils.apply_warp to map the atlas_t1mni onto the t1w brain, creating aligned_atlas_skull
					4. Then use reg_utils.align to map the averaged B0 file into the aligned_atlas_skull, creating the .dwi_aligned_atlas
					5. If the steps 3-4 fail, then just use reg_utils.align and reg_utils.combing_xfms to accomplish that same task
					
					
		
			
	dmri_reg_old <Class>
		
		Inputs:
		
		Description:
		
			dwi2atlas():
			
			
		Outputs:
		
	direct_streamline_norm():
		Inputs:
			streams = path to streamline.trk file
			fa_path = path to FA tensor image
			namer = name_resource variable
		Decription:
			1. Load in FA image and the reference FA image (located in .../atlases/reference_brains/)
			2. Use reg_utils.wm_syn() in order to get the Diffeomorphic map and affine map for transforming the FA image into the reference FA image
			3. Edit the affine map by:
				1. making a copy of it
				2. inverting the x and y planes of the copy
				3. scaling the z plane by the voxel size
				4. scaling the y plane by the square of the voxel size
			4. Use the function dipy.tracking.streamline.deform_streamlines to warp the streamlines into the reference FA space
			5. save the streamlines
		Output:
			mapping = DiffeomorphicMap for FA to template
			affine_map = AffineMap for Fa to template
		
		
gen_track.py
Purpose:

	run_track <class>
		Creates a variable to contain the detereministic tractography
		
			run():
				Inputs:
					dwi_in = path to the input dwi image
					nodif_B0_mask = path to the b0 mean volume mask
					gm_in_dwi = path to grey matter segmentation in EPI space
					vent_csf_in_dwi = path to ventricular CSF mask in EPI space
					csf_in_dwi = path to the csf mask
					wm_in_dwi = path to white matter probabilities
					gtab = gradient table made from bvec and bval
					mod_type = model type
					track_type = tracking approach
					mod_func = diffusion model
					seeds = seeds for tractography
					stream_affine = 4x4 2D array
				Description:
					1. Prepare for the use of tracks by creating a tissue classifier using prep_tracking()
					2. depending on what you have specified for your track_type and mod_type, run the matching dipy analysis programs
					3. return tractography tracks data in the form of an ArraySequence
					
				Output:
					tracks = tractography tracks
				
			prep_tracking():
				Inputs:
				
				Description:
					1. Loads in the dwi data from the file
					2. Load in tissue maps for the gm, wm, csf and convert them to arrays to serve as masks
					3. Depending on the tissue class you specify, call the respective tissue classifier to make 
				Output:
					self.tiss_classifier = tissue classifier object, depends on what tissue class you use
			




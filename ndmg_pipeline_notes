Getting Started:

The ndmg pipeline can be used to generate connectomes as a command-line utility on BIDS datasets with the following command:

ndmg_bids /input/bids/dataset /output/directory participant

Note that more options are available which can be helpful if running on the Amazon cloud, which can be found and documented by running ndmg_bids -h. If you do not have a BIDS organized dataset, you an use a slightly more complicated interface which is made available and is documented with ndmg_pipeline -h.
If running with the Docker container shown above, the entrypoint is already set to ndmg_bids, so the pipeline can be run directly from the host-system command line as follows:
docker run -ti -v /path/to/local/data:/data bids/ndmg /data/ /data/outputs participant


Questions/Difficulties:
- In ndmg_bids.session_level, what is being done in args = [[ dw, bval, bvec, anat,...] for (dw, bval, bvec, anat) in zip(dwis, bvals, bvecs, anats)] ?
- What on earth is bids_utils.flatten() doing? It appears to just retrieve the path to the output directory?
- In ndmg_dwi_pipeline, around line 210 the variable 'nodif_B0_iso_path' is assigned a value. This appears to never be used?
- What is the purpose of gen_utils.execute_cmd? It appears to open a bash command and and execute whatever string is fed to it.
- In gen_utils.reorient_t1w(), in the first several lines a random string is generated and put into the path for the t1w files. Why do that?
- gen_utils.reorient_dwi() and reorient_t1w( ) runs several command line fsl functions
- In gen_utils.make_gtab_and_bmask( ) 'fslroi' and 'bet' commands are run from the command line
- gen_reg.gen_tissue() executes 'fslmaths' commands
- reg_utils.t1w_skullstrip executes '3dSkullStrip' commands
- the gen_reg.dmri_reg class contains the namer class, is there anyway to just combine them at the beginning?
- reg_utils.segment_t1w executes 'fast' commands
- Pretty much all of reg_utils.py executes command line AFNI or FSL functions
- gen_reg.dmri_reg.gen_tissue executes 'fslmaths' command
- gen_reg.dmri_reg.t1w2dwi_align uses the 'convert_xfm' command, need to look into whether that is part of fsl
-
-



The notes below give a simplified explaination of the process the pipeline follows:

ndmg_bids.py
Purpose: Starting point of the ndmg pipeline, assuming you are using a BIDS organized dataset

	main( )
		Inputs:
			Run [ndmg_bids -h] to get a full list of potential inputs. Required inputs are:
			bids_dir = path to the BIDS formated directory containt the input dataset
			output_dir = desired location of the output directories
			{participant, group} = level of the analysis that will be performed
			
		Description:
			1. Reads in the inputs given by the user
			2. Determines if a s3 bucket is being called and if the path provided is valid. If it is then it reads it in.
			3. Passes inputs onto session_level( ) for further analysis
		Outputs:
			User input parameters



	session_level( )
		Inputs:
			User input parameters from main( )
		Description:
			1. Sends atlas directory, modality, and voxel_size to get_atlas( )
			2. Recieves labels, reference brain, reference mask, atlas brain and lv_mask from get_atlas( )
			3. Sorts through the reference files to only select the ones that match atlas_select's atlas (i.e. deskian)
			4. Uses sweep_directory( ) to get the paths for the dwi, anat, bval and bvec files.
			5. Depending on the modality specified by the user:
				1. For dwi data, create a list 'args' which contains the location of the dwi, bvec, bval, anatomical, reference, mask, and output directory
				2. For func data, create a list 'args' which contains the locations of the func, anatomical, reference, atlas brain, atlas brain mask, lv_mask, labels, and output directory 
			6. Print out what is in args to double-check paths and files
			7. Send relevant files to ndmg_dwi_pipeline()
			8. Removed files determined to be deleted by user (debug = False, big =False, etc.)
		Outputs:
			None
			
			
	get_atlas( )
		Inputs:
			atlas_dir = the directory containing the atlases
			modality = what you are analyzing, "dwi" or "func"
			vox_size = the voxel size to use for template registrations
		Description:
			1. Check if specified voxel size is 2mm or 1mm, if it is then set dimension 'dims' to '2x2x2' or '1x1x1' respectfully. If voxel size given is different from either of those choices, raise an Error
			2. If the modality is set to 'dwi', make sure that the atlas directory exists (if it doesn't, download it from github.com/neurodata/neuroparc.git) then go throught the atlas directory and assign:
				1. atlas = T1 weighted mask of reference brains of the given resolution
				2. atlas_mask = T1 weighted mask of reference brains of the given resolution
				3. labels = labeling files for various areas of the brain depending on your atlas choice
			3. If the modality is set to 'func', then go through the atlas directory to find the same info [CURRENTLY COMMENTED OUT]
			4. Check to make sure that all the reference files exist before organizing them to return to session_level( )
		Outputs:
			labels = list of locations of label files for atlases of relevant voxel resolution
			atlas = location of atlas brain
			atlas_mask = location of atlas brain_mask
			atlas_brain = [CURRENTLY NOT MADE]
			lv_mask = [CURRENTLY NOT MADE, DEFAULT = NoneType]


bids_utils.py
Purpose:






ndmg_dwi_pipeline.py
Purpose: To create a brain connectome graph from MRI data. This program is where the majority of the analysis is facilitated.

	ndmg_dwi_pipeline( )
		Inputs:
		    
		Description:
			1. Print all inputs received from ndmg_bids.py and double check that all variables are assigned something
		    	2. Create “namer”, a variable of the name_resource class in bids_utils.py. Namer contains all of the path and settings information for the desired run. It includes: subject, anatomical scan, session, run number, task, resolution, output directory. It also contains functions to edit and recall information contained within
		    	3. Check if the output directory exists, if not then create the directory
		    	4. Create the directory tree required for placing the outputs of the analysis and add them to namer
		    	5. Create derivative and connectome output file names. If you have decded to make big graphs, create paths for those files as well
		    	6. Begin Preprocessing by performing eddy correction, deleting prexisting dwi files. The commands to run FSL’s eddy_correct program and written into the terminal and the system is then asked to execute the task on the terminal using os.system(cmd). Eddy correct data is placed into the output directory.
			7. Copy the input bval and bvec files into the output/prep_dwi directory for future use
    			8. Use dipy.io to check that the bvec and bval files aren’t corrupted. This is done by making sure that anywhere in the array bvals = 0, bvecs = 0. If there is any point where bvals > 50 and the corresponding bvector is [0,0,0], throw an error.
    			9. Rescale the bvecs using rescale_bvec.py in ndmg.preproc, which works by:
        			1. making sure that the bvec array has the dimensions X rows and 3 columns, otherwise it transposes it
        			2. normalizing any value in in bvec that doesn’t have a vector norm close to 0
        			3. save rescaled bvec data to bvec_scaled.bvec file in /output/dwi/preproc/
    			10. Determines the orientation of the preprocessed dwi files by sending them to gen_utils.reorient_dwi( ) and receiving the potentially changed dwi_prep and bvec file paths
    			11. Check the voxel resolution using gen_utils.match_target_vox_res( ) and potentially reslice dwi_prep images
    			12. Build a gradient table using gen_utils.make_gtap_and_bmask( )
    			13. Get b0 header and affine from dwi eddy corrected file
			14. Begin analysis of anatomical data by checking to make sure that there are no pre-existing directories with names of what the program will be using. If there are, this program will delete it.
    			15. Reorient the t1w data if necessary by using gen_utlis.reorient_t1w( ), getting the potentially edited path to t1w data back
    			16. Determine where to calculate the tractography (reg_style): native = map atlas to subject, native-DSN = map streamlines to atlas, mni = map subject to atlas
				1. If reg_style = native or native-DSN. Create gen_reg.dmri_reg class 'reg', this class contains many methods that will be used
				2. Use reg.gen_tissue to extract the brain from the raw t1w image, create WM, GM, and CSF masks, reslices all 4 files to the target voxel resolution and extracts the white matter edge
				3. Use reg.t1w2dwi_align to 
			17. 
			
		Outputs:



gen_utils.py
Purpose: General functions to be used during the pipeline

	reorient_dwi( )
		Inputs:
			dwi_prep = location of the eddy corrected dwi data
			bvecs = location of the rescaled bvec file
			namer = the namer variable containing all relevant naming data
		Description:
		    	1. uses os.poopen to open dwi_prep and read the first line of the file, this returns what orientation convention the data is using (Neurological or Radiological)
    			2. copy dwi_prep and bvecs files into the same output directory but with new names, these will be the files that are re-orientated
    			3. run os.popen to open dwi_prep and get the qform string (vectors describing how the data is related to realspace)
    			4. Convert the dwi_prep data to the Radiological format and then reorient it. The same steps are taken whether or not it is in Radiological format, with a simple calling of fslorient -forceradiological added at the end if it isn’t. Reorientation includes:
        			1. Looking at the qform to determine whether it needs Posterior-Anterior Reorientation (-x -y z)or Inferior-Superior Reorientation (-x y -z). If it doesn’t, then these steps are skipped.
        			2. calling fslswapdim to reorient the data and save it as either /output/prep_dwi/dwi_reor_Pa.nii.gz or .../dwi_reor_IS.nii.gz
        			3. changing the bvecs accordingly to account for the reorientation ans saving them over the existing bvec files
        			4. saving the new dwi files over the existing ones if reorientation occurred
        		5. return values
		Outputs:
			dwi = location of eddy corrected and potentially reoriented dwi data
			bvecs = location of b-vector file, potentially reorientated if dwi data was

	match_target_vox_res( )
		Reslices input MRI file if it doesn’t match the targeted voxel resolution. Can take dwi or t1w scans.
		Inputs:
			img_file = path to image file you want to analyze
			vox_size = voxel size you
			namer = the namer variable containing all relevant naming data
			sens = the format of the image file
		Description:
    			1. imports reslice from dipy.align.reslice
    			2. load the image file and get various parameters from it (affine, header, zooms)
    			3. determine if the given voxel size (zooms) is either 1mm or 2 mm. If it is not then:
        			1. copy the existing image file to the same directory, adding “_pre_res” to the end of it
        			2. run dipy’s reslice function on the data to get it to the new resolution, then take the data and nibable.Nifti1Image to convert the data into a image file that you can save over the existing image file. Also include the qform, sform, and header information into the nifti file
		Outputs:
			img_file = path the the image file that may have been resliced

	make_gtab_and_bmask( )
		Takes bval and bvec files and produces a structure in dipy format
		Inputs:
			fbval = path to bval
			fbvec = path to bvec 
			dwi_file = path to dwi file
			outdir = path to were you want the output files saved
		Description:
    			1. read in bval and bvec data
    			2. create a gradient table from that data using gradient_table from dipy and set the b0 threshold to the minimum bval value
    			3. Locate where the b0 indices are by looking for where in bval it equals the threshold
   			4. Extract and combine all the b0s collected from the dwi file using fslroi and saving the output filed into /output/dwi/preproc/#_B0.nii.gz
    			5. Take all the b0s and average them and save the resulting image into /output/dwi/preproc/nodif_B0.nii.gz
    			6. Then take the average image and generate a b0 brain mask using bet
    			7. Return relevant data
		Outputs:
			gtab = gradient table
			nodif_B0 = path to averaged b0 image
			nodif_B0_mask = b0 brain mask
			
			
gen_reg.py
Purpose:

	dmri_reg <Class>
		Creates a variable containing all the pathing information required for tractography
		Inputs:
			namer = the namer variable containing BIDS directory tree
			nodif_B0 = path to the b0 brain mask
			t1w_in = path to t1w scan to be analyzed
			vox_size = voxel size (in the form of ‘2mm’)
			simple = simple
		Description:
			1. take in relevant pathing strings and create an expansive list of paths for the various outputs about to be generated by the pipeline
    			2. Run class modules below for tractography analysis
			
			gen_tissue():
				Inputs:
					none
				Description:
					1. Extracts brain from raw t1w data and saves it as a seperate file with the "AFNI's 3dSkullStrip algorithm" in reg_utils.t1w_skullstrip()
					2. Takes the extracted brain and segments it into probability maps using reg_utils.segment_t1w(), which runs FSL's FAST to segment the image into the grey matter, white matter, and CSF probability maps (masks). It returns the location of the segmented files ('.../output/anat/preproc/t1w_seg/pve*')
					3. Use gen_utils.match_target_vox_rex( ) to reslice the extracted t1w brain image, white matter mask, grey matter mask, and csf mask and save them
					4. Filter the white-matter mask so that any value below 0.2 is ignored (this ignores all non-white-matter) and use fslmaths to extracte the white matter edge and save it					
				Output:
					
			t1w2dwi_align():
				Inputs:
					none
				Description:
					1. Use reg_utils.align() to run FSL's flirt command on the extracted t1w brain to allign it with the MNI template of the same voxel resolution and save the transform matrix to '.../output/tmp/reg_m/xfm_t1w2mni_init.mat'
					2. Attempt to perform a non-linear registration of the t1w image to the MNI template.
				Output:
			
			atlas2t1w2dwi_align():
				Inputs:
				
				Description:
				
				Output:
			tissue2dwi_align():
				 Inputs:
				
				Description:
				
				Output:
		
			
	dmri_reg_old <Class>
		
		Inputs:
		
		Description:
		
			dwi2atlas():
			
			
			
		
		Outputs:
		
